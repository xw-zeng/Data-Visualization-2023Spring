{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Topic Modeling \n",
    "\n",
    "We will be using the 20 newsgroups dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 20 newsgroups dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_raw = pkl.load(open('20news.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello World,\\n\\t     just bought a new Stealth two weeks ago. Got a grad student \\n rebate. Someone told me that there's another $400 reabet for 1st time\\n Chrysler buyer. True ? If yes can I still get it or am I too late ?\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_raw[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining $ùëò$ Topical Terms from Collection $ùê∂$\n",
    "\n",
    "Utilize TF-IDF as your scoring function!\n",
    "\n",
    "With [sklearn.feature_extraction.text.TfidfVectorizer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             stop_words=\"english\",\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.5,\n",
    "                             min_df=10)\n",
    "X = np.array(vectorizer.fit_transform(docs_raw).todense())\n",
    "terms_name = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = terms_name[np.max(X, axis=0) > 0.55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "print(len(topics))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Topic Coverage $\\pi_{ùëñùëó}$ of $i$-th document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=topics)\n",
    "count_X = count_vectorizer.fit_transform(docs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3273, 541)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5],\n",
       "        [ 7],\n",
       "        [ 1],\n",
       "        ...,\n",
       "        [14],\n",
       "        [ 4],\n",
       "        [11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(count_X, axis = 1) # ÊØè‰∏™documentÈáåÂΩí‰∏ÄÂåñÁöÑÂàÜÊØç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirito/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py:665: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage = np.array(count_X / np.sum(count_X, axis = 1))\n",
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1], [2,2], [3,3]])\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a story.  I bought a car about two weeks ago.  I finally can\n",
      "get hold of the previous owner of the car and got all maintanence\n",
      "history of the car.  In between '91 and '92, the instrument pannel \n",
      "of the car has been replaced and the odometer also has been reset\n",
      "to zero.  Therefore, the true meter reading is the reading before\n",
      "replacement plus current mileage.  That shows 35000 mile difference\n",
      "comparing to the mileage on the odometer disclosure from.  The \n",
      "dealer never told me anything about that important story.\n",
      "\n",
      "I hope that I can return the car with full refund.  Do u think this\n",
      "is possible?  Does anyone have similar experiences?  Any comments\n",
      "will be appreciated.  Thanks.\n"
     ]
    }
   ],
   "source": [
    "doc = -1\n",
    "print(docs_raw[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Doc, topic: ['car' 'dealer' 'difference' 'similar' 'thanks' 'think' 'weeks']\n",
      "This Doc, coverage: [0.45454545 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909]\n"
     ]
    }
   ],
   "source": [
    "nonzero_index = np.array(coverage[doc] != 0).flatten()\n",
    "print('This Doc, topic:', topics[nonzero_index])\n",
    "print('This Doc, coverage:', coverage[doc][nonzero_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
